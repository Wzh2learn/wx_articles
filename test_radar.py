"""
ğŸ§ª é€‰é¢˜é›·è¾¾å•å…ƒæµ‹è¯•è„šæœ¬
åªæµ‹è¯• fetch_dynamic_trends å‡½æ•°ï¼Œä¸æ¶ˆè€— Tavily é¢åº¦ï¼Œä¸è¿è¡Œå®Œæ•´æµç¨‹ã€‚
"""
import sys
import os
import httpx
from openai import OpenAI

# å¯¼å…¥é…ç½®
from config import DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL, PROXY_URL, REQUEST_TIMEOUT

# æ¨¡æ‹Ÿç¯å¢ƒå¼•å…¥
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from agents.trend_hunter import fetch_dynamic_trends, WebSearchTool

def test_radar():
    print("ğŸ§ª æ­£åœ¨å¯åŠ¨é›·è¾¾å•å…ƒæµ‹è¯•...")
    print(f"ğŸ”Œ ä»£ç†é…ç½®: {PROXY_URL}")
    print(f"ğŸ”‘ API Key: {DEEPSEEK_API_KEY[:5]}******")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    try:
        if PROXY_URL:
            http_client = httpx.Client(proxy=PROXY_URL, timeout=REQUEST_TIMEOUT)
        else:
            http_client = httpx.Client(timeout=REQUEST_TIMEOUT)
            
        client = OpenAI(
            api_key=DEEPSEEK_API_KEY, 
            base_url=DEEPSEEK_BASE_URL, 
            http_client=http_client
        )
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # åˆå§‹åŒ– Tavily å·¥å…·
    search_tool = WebSearchTool()

    # è¿è¡ŒæŠ“å–
    try:
        keywords = fetch_dynamic_trends(client, search_tool)
        
        print("\n" + "="*50)
        print("ğŸ‰ æµ‹è¯•ç»“æœæŠ¥å‘Š")
        print("="*50)
        
        if keywords:
            print(f"âœ… æˆåŠŸæ•è· {len(keywords)} ä¸ªçƒ­è¯:")
            for i, kw in enumerate(keywords, 1):
                print(f"   {i}. {kw}")
        else:
            print("âš ï¸ æœªæ•è·åˆ°ä»»ä½•å…³é”®è¯ (è¯·æ£€æŸ¥ç½‘ç»œæˆ– Jina æœåŠ¡çŠ¶æ€)")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_radar()