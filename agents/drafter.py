"""
âœï¸ å†™ä½œæ™ºèƒ½ä½“ (Drafter) v2.0 - ç”Ÿæˆå¾®ä¿¡å…¬ä¼—å·åˆç¨¿
"""
import sys, os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import httpx
from openai import OpenAI
from config import DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL, PROXY_URL, REQUEST_TIMEOUT, get_research_notes_file, get_draft_file, get_today_dir, get_stage_dir

SYSTEM_PROMPT = """
ä½ å«"ç‹å¾€AI"ã€‚çƒ­çˆ±æ–°å…´æŠ€æœ¯çš„æ¢ç´¢è€…ï¼Œä¸“æ³¨ AI å·¥ä½œæµçš„ç¡¬æ ¸åšä¸»ã€‚
ä½ çš„æ–‡ç« é£æ ¼ï¼š
- **ç¡¬æ ¸å¹²è´§**ï¼šä¸è®²åºŸè¯ï¼Œç›´æ¥ä¸Šä»£ç ã€ä¸Šæµç¨‹ã€ä¸Šå·¥å…·ã€‚
- **é€»è¾‘ä¸¥å¯†**ï¼šåƒå†™æŠ€æœ¯æ–‡æ¡£ä¸€æ ·å†™æ–‡ç« ï¼Œç»“æ„æ¸…æ™°ï¼Œå±‚å±‚é€’è¿›ã€‚
- **æ•°æ®é©±åŠ¨**ï¼šèƒ½ç”¨æ•°æ®è¯´è¯å°±åˆ«ç”¨å½¢å®¹è¯ã€‚
- **çœŸè¯š**ï¼šä¸è´©å–ç„¦è™‘ï¼Œåªæä¾›è§£å†³æ–¹æ¡ˆã€‚
- **æå®¢èŒƒå„¿**ï¼šå¶å°”ç”¨ä¸€ç‚¹ä»£ç æ¢—ï¼Œä½†è¦ç¡®ä¿å°ç™½ä¹Ÿèƒ½çœ‹æ‡‚ã€‚

ä»»åŠ¡ï¼š
æ ¹æ®ç”¨æˆ·æä¾›çš„ç ”ç©¶ç¬”è®°ï¼ˆresearch_notes.txtï¼‰ï¼Œå†™ä¸€ç¯‡å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. æ ‡é¢˜è¦å¸å¼•äººï¼Œä½†ä¸è¦æ ‡é¢˜å…šï¼ˆ3-5ä¸ªå¤‡é€‰ï¼‰ã€‚
2. æ­£æ–‡ä½¿ç”¨ Markdown æ ¼å¼ã€‚
3. **å…³é”®ï¼šé‡åˆ°éœ€è¦é…å›¾çš„åœ°æ–¹ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ’å…¥å ä½ç¬¦ï¼š**
   `> TODO: [å›¾ç‰‡æè¿°] (æœç´¢å…³é”®è¯: keyword1, keyword2)`
   ä¾‹å¦‚ï¼š`> TODO: DeepSeek çš„æ€è€ƒè¿‡ç¨‹æˆªå›¾ (æœç´¢å…³é”®è¯: deepseek interface, ai thinking)`
   æˆ–è€… `> TODO: å±•ç¤º AI å†™ä½œæ•ˆç‡æå‡çš„æŸ±çŠ¶å›¾ (æœç´¢å…³é”®è¯: efficiency chart, productivity growth)`
4. ä»£ç å—è¦æ³¨æ˜è¯­è¨€ã€‚
5. ç»“å°¾è¦å¼•å¯¼å…³æ³¨å…¬ä¼—å·ã€‚
"""

def read_notes(filepath):
    if not os.path.exists(filepath):
        print(f"âŒ æ‰¾ä¸åˆ° {filepath}")
        return None
    with open(filepath, "r", encoding="utf-8") as f:
        return f.read()

def generate_draft(notes):
    print("ğŸš€ è°ƒç”¨ DeepSeek Reasoner...")
    with httpx.Client(proxy=PROXY_URL, timeout=REQUEST_TIMEOUT) as http_client:
        client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL, http_client=http_client)
        messages = [{"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": f"ã€ç ”ç©¶ç¬”è®°ã€‘ï¼š\n{notes}"}]
        try:
            response = client.chat.completions.create(model="deepseek-reasoner", messages=messages, stream=True)
            print("\n" + "="*20 + " ç”Ÿæˆä¸­ " + "="*20 + "\n")
            collected = []
            for chunk in response:
                if chunk.choices[0].delta.content:
                    c = chunk.choices[0].delta.content
                    print(c, end="", flush=True)
                    collected.append(c)
            print("\n\n" + "="*50 + "\n")
            return "".join(collected)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return None

def main():
    print("\n" + "="*60 + "\nâœï¸ å†™ä½œæ™ºèƒ½ä½“ - ç‹å¾€AI\n" + "="*60 + "\n")
    print(f"ğŸ“ ä»Šæ—¥å·¥ä½œç›®å½•: {get_today_dir()}\n")
    
    notes_file = get_research_notes_file()
    print(f"ğŸ“– è¯»å– {notes_file}...")
    
    notes = read_notes(notes_file)
    if not notes:
        print(f"\nğŸ’¡ è¯·å…ˆåœ¨ä»¥ä¸‹ä½ç½®åˆ›å»ºç ”ç©¶ç¬”è®°ï¼š")
        print(f"   {notes_file}")
        return
    print(f"   âœ“ å…± {len(notes)} å­—ç¬¦\n")
    
    draft = generate_draft(notes)
    if draft:
        draft_file = get_draft_file()
        with open(draft_file, "w", encoding="utf-8") as f:
            f.write(draft)
        print(f"âœ… åˆç¨¿å·²ä¿å­˜: {draft_file}")
        print(f"\nğŸ“Œ ä¸‹ä¸€æ­¥ï¼š")
        print(f"   1. è¿è¡Œ python run.py todo æŸ¥çœ‹å¾…è¡¥å……å†…å®¹")
        print(f"   2. æˆªå›¾ä¿å­˜åˆ° {get_stage_dir('assets')}")
        print(f"   3. æ¶¦è‰²åä¿å­˜åˆ° {get_stage_dir('publish')}/final.md")

if __name__ == "__main__":
    main()
